{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overview_section"
      },
      "source": [
        "# LLM Auto-Prompt Tuning for Code Generation\n",
        "\n",
        "This notebook demonstrates the applications of prompt-tuning Large Language Models (LLMs) with a focus on code generation. It serves as both an educational tool and a practical guide, walking you through various stages from basic model usage to advanced training techniques.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The notebook is organized into five main stages:\n",
        "\n",
        "1. **Code Generation with Base Prompt**: Demonstrate basic code completion using a general-purpose model\n",
        "2. **Data Preparation**: Generate code to download relevant datasets for LLM training\n",
        "3. **Training Data Preprocessing**: Generate code to preprocess data for LLM training\n",
        "4. **Run Auto-Prompt Tuning job to get optimized prompt**: Fetch optimized prompt using base prompt and prompt tuning dataset\n",
        "\n",
        "Each stage builds upon the previous one, providing a comprehensive understanding of the LLM training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by installing the necessary dependencies and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets accelerate torch evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "import time\n",
        "import json\n",
        "from IPython.display import display, HTML, Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 1: Demonstrate basic code completion using a general-purpose model\n",
        "\n",
        "***Use the following prompt in the next code cell to generate code***\n",
        "\n",
        "```bash\n",
        "Create python script to download a dataset from Hugging Face and save it as a CSV.\n",
        "1. Use the dotenv library to load an environment variable named \"HF_ACCESS_TOKEN\".\n",
        "2. Download the 'train' split of the \"Jayveersinh-Raj/prompt-tuning-text-to-code\" dataset. Use the token for authentication.\n",
        "3. Create a 'data' directory if it doesn't exist.\n",
        "4. Save the dataset into the 'data' directory as \"prompt_tuning_train.csv\". Do not include the DataFrame index.\n",
        "5. Print a success message with the final file path.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 2: Generate code to download relevant datasets for LLM training\n",
        "\n",
        "***Use the following prompt in the next code cell to generate code***\n",
        "\n",
        "```bash\n",
        "Goal: Format the raw data into a structured training prompt.\n",
        "\n",
        "1. Import pandas to read the CSV file.\n",
        "2. Load the \"data/prompt_tuning_train.csv\" into a pandas DataFrame.\n",
        "3. Display the first 5 rows of the DataFrame to inspect the columns.\n",
        "\n",
        "    (The columns should be 'bad_prompts' and 'improved_prompts')\n",
        "\n",
        "1. Define a function create_training_prompt(row) that takes a row of the DataFrame as input.\n",
        "2. Inside the function, format the data into a clear structure:\n",
        "    1. Start with a system instruction: \"Rewrite the user's initial request into a refined prompt.\"\n",
        "    2. Add a \"### Initial Request:\" section using the value from the 'bad_prompts' column.\n",
        "    3. Add a \"### Refined Prompt:\" section using the value from the 'improved_prompts' column.\n",
        "3. The function should return the complete formatted string.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 3: Generate code to preprocess data for LLM training\n",
        "\n",
        "***Use the following prompt in the next code cell to generate code***\n",
        "\n",
        "```bash\n",
        "Now apply the formatting function to the DataFrame.\n",
        "1. Create a new column 'formatted_prompt' in the DataFrame.\n",
        "2. Apply the `create_training_prompt` function to each row of the DataFrame to populate the new column.\n",
        "3. Print the content of the 'formatted_prompt' column for the first row to verify the output.\n",
        "4. Save the processed DataFrame with the new column to \"data/prompt_tuning_train_processed.jsonl\" in JSON Lines format, with orient='records' and lines=True.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps_section"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that we have set up the notebook environment and implemented the core utility functions, we can proceed to the next tasks:\n",
        "\n",
        "1. Show the limitations of basic prompts for code generation\n",
        "2. Compare with optimized prompts\n",
        "3. Analyze the differences in performance\n",
        "\n",
        "These will be implemented in the subsequent sections of this notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
